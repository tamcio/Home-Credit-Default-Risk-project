{
 "cells": [
  {
   "cell_type": "code",
   "id": "0ac8a23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T00:48:19.339687Z",
     "start_time": "2026-01-21T00:48:19.337664Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "555bd31e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T21:57:32.594768Z",
     "start_time": "2026-01-20T21:57:30.921014Z"
    }
   },
   "source": [
    "path = '../home-credit-default-risk/'\n",
    "df = pd.read_csv(path + 'application_train.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "25e2a1ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T21:57:33.063572Z",
     "start_time": "2026-01-20T21:57:33.060840Z"
    }
   },
   "source": [
    "def prepare_data(df, drop=False):\n",
    "    df_temp = df.copy()\n",
    "    \n",
    "    if drop:\n",
    "        missing = df_temp.isna().mean()\n",
    "        drop_cols = missing[missing > 0.5].index\n",
    "        df_temp = df_temp.drop(columns=drop_cols)\n",
    "    \n",
    "    y = df_temp['TARGET']\n",
    "    X = df_temp.drop('TARGET', axis=1)\n",
    "    \n",
    "    X = pd.get_dummies(X, dummy_na=True)\n",
    "    \n",
    "    # because of NaNs we need to use the imputer\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    x_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x_imputed)\n",
    "    \n",
    "    return x_scaled, y"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6a0df958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T00:49:06.143848Z",
     "start_time": "2026-01-21T00:49:06.141274Z"
    }
   },
   "source": [
    "def train_and_eval(X, y, model_type='logistic'):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(max_iter=100)\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_type == 'gradient_boosting':\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    score = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return score"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Logistic regression\n",
    "\n",
    "Without droping any columns"
   ],
   "id": "239286183ed4d577"
  },
  {
   "cell_type": "code",
   "id": "945b2c6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T00:49:58.347304Z",
     "start_time": "2026-01-21T00:49:44.508384Z"
    }
   },
   "source": [
    "X1, y1 = prepare_data(df, drop=False)\n",
    "score_1 = train_and_eval(X1, y1)\n",
    "print(f\"ROC AUC: {score_1:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7484\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "1ccb25b2",
   "metadata": {},
   "source": "With droping columns that are >50% null"
  },
  {
   "cell_type": "code",
   "id": "657f2534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T00:50:09.576200Z",
     "start_time": "2026-01-21T00:49:58.391352Z"
    }
   },
   "source": [
    "X2, y2 = prepare_data(df, drop=True)\n",
    "score_2 = train_and_eval(X2, y2)\n",
    "print(f\"ROC AUC: {score_2:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7451\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ensemble methods",
   "id": "9ebaf7c1b3413804"
  },
  {
   "cell_type": "code",
   "id": "65de2e86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T00:50:13.344175Z",
     "start_time": "2026-01-21T00:50:09.634206Z"
    }
   },
   "source": [
    "score_3 = train_and_eval(X1, y1, 'random_forest')\n",
    "print(f\"ROC AUC: {score_3:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7364\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-21T00:54:56.561169Z",
     "start_time": "2026-01-21T00:50:13.391732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "score_4 = train_and_eval(X1, y1, 'gradient_boosting')\n",
    "print(f\"ROC AUC: {score_4:.4f}\")"
   ],
   "id": "d12e994b4801745f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7570\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We see that baseline model - logistic regression even without any feature engineering and without any feature selection is getting roc auc of 0.74.\n",
    "\n",
    "Random forest achieved worse score of 0.73.\n",
    "\n",
    "Gradient boosting achieved the best score of almost 0.76.\n",
    "\n",
    "On kaggle competition the best score is 0.806."
   ],
   "id": "c15a92a6f8f675c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c72d3e665a7a652"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
